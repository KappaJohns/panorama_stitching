{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imregionalmax(image, kernel=None):\n",
    "    \"\"\"Find the regional max of the image. An approximation of MATLAB's\n",
    "    imregionalmax function. Result only differs when surrounding pixels\n",
    "    have the same value as the center.\n",
    "\n",
    "    Parameters:\n",
    "    - image: the input image\n",
    "    - kernel: the size of the neiborhood region, default is 3x3, i.e.\n",
    "              neighboring 8 pixels.\n",
    "    Returns:\n",
    "    - a bitmask image, where '1' indicates local maxima.\n",
    "    Author:\n",
    "    - Yu Fang\n",
    "    References:\n",
    "    - https://github.com/bhardwajvijay/Utils/blob/master/utils.cpp\n",
    "    - https://stackoverflow.com/questions/5550290/find-local-maxima-in-grayscale-image-using-opencv\n",
    "    \"\"\"\n",
    "    # dialate the image so that small values are replaced by local max\n",
    "    local_max = cv2.dilate(image, kernel)\n",
    "    # non-local max pixels (excluding pixel w/ constant 3x3 neighborhood)\n",
    "    # will be replaced by local max, so the values will increase. remove them.\n",
    "    # so the result is either local max or constant neighborhood.\n",
    "    max_mask = image >= local_max\n",
    "    # erode the image so that high values are replaced by local min\n",
    "    local_min = cv2.erode(image, kernel)\n",
    "    # only local min pixels and pixels w/ constant 3x3 neighborhood\n",
    "    # will stay the same, otherwise pixels will be replaced by the local\n",
    "    # min and become smaller. We only take non-local min, non-constant values.\n",
    "    min_mask = image > local_min\n",
    "    # boolean logic hack\n",
    "    #   (local max || constant) && (!local min && !constant)\n",
    "    # = local max && !local min && !constant\n",
    "    # = local max && !constant\n",
    "    return (max_mask & min_mask).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def est_homography(src, dest):\n",
    "    \"\"\" Compute the homography matrix from (x_src, y_src) to (x_dest, y_dest).\n",
    "    Parameters:\n",
    "    - src: (x,y) coordinates of N source pixels, where coordinates are row vectors,\n",
    "           so the matrix has dimension Nx2 (N>=4).\n",
    "    - dest: (x,y) coordinates of N destination pixels, where coordinates are row vectors,\n",
    "            so the matrix has dimension Nx2 (N>=4).\n",
    "    Returns:\n",
    "    - the homography matrix such that H @ [x_src, y_src, 1].T = [x_dest, y_dest, 1].T\n",
    "    Author:\n",
    "    - Yu Fang\n",
    "    \"\"\"\n",
    "    N = src.shape[0]\n",
    "    if N != dest.shape[0]:\n",
    "        raise ValueError(\"src and diff should have the same dimension\")\n",
    "    src_h = np.hstack((src, np.ones((N, 1))))\n",
    "    A = np.array([np.block([[src_h[n], np.zeros(3), -dest[n, 0] * src_h[n]],\n",
    "                            [np.zeros(3), src_h[n], -dest[n, 1] * src_h[n]]])\n",
    "                  for n in range(N)]).reshape(2 * N, 9)\n",
    "    [_, _, V] = np.linalg.svd(A)\n",
    "    # take the right singular vector x corresponding to the least singular value\n",
    "    # s.t. ||Ax - 0||^2 is minimized\n",
    "    return V.T[:, 8].reshape(3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_homography(H, src):\n",
    "    \"\"\" Apply the homography H to src\n",
    "    Parameters:\n",
    "    - H: the 3x3 homography matrix\n",
    "    - src: (x,y) coordinates of N source pixels, where coordinates are row vectors,\n",
    "           so the matrix has dimension Nx2 (N>=4).\n",
    "    Returns:\n",
    "    - src: (x,y) coordinates of N destination pixels, where coordinates are row vectors,\n",
    "           so the matrix has dimension Nx2 (N>=4).\n",
    "    Author:\n",
    "    - Yu Fang\n",
    "    \"\"\"\n",
    "    src_h = np.hstack((src, np.ones((src.shape[0], 1))))\n",
    "    dest =  src_h @ H.T\n",
    "    return (dest / dest[:,[2]])[:,0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawMatches(image1, kp1, image2, kp2, idx_pairs):\n",
    "    \"\"\"A wrapper around OpenCV's drawMatches.\n",
    "    \n",
    "    Parameters:\n",
    "    - image1: the first image\n",
    "    - kp1: *matrix indices* of the keypoints from image 1\n",
    "           (Nx2 numpy array, where N is the number of keypoints)\n",
    "    - image2: the second image\n",
    "    - kp2: *matrix indices* of the keypoints from image 2 \n",
    "           (Nx2 numpy array, where N is the number of keypoints)\n",
    "    - idx_pairs: pairs of matching indices, e.g. if kp1[3] \n",
    "                 matches kp2[5], then idx_pairs=[[3,5],...]\n",
    "                 (Kx2 numpy array, where K is the number of matches)\n",
    "    Returns:\n",
    "    - an image showing matching points\n",
    "    Author:\n",
    "    - Yu Fang\n",
    "    \"\"\"\n",
    "    # note that the coordinates are reversed because the difference\n",
    "    # between matrix indexing & coordinates.\n",
    "    keypt1 = [cv2.KeyPoint(coord[1], coord[0], 40) for coord in kp1.tolist()]\n",
    "    keypt2 = [cv2.KeyPoint(coord[1], coord[0], 40) for coord in kp2.tolist()]\n",
    "    matches = [cv2.DMatch(pair[0], pair[1], 0) for pair in idx_pairs.tolist()]\n",
    "    return cv2.drawMatches(image1, keypt1, image2, keypt2, matches, None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [],
   "source": [
    "def amns(cornerImage, n_best):\n",
    "    c_robust = 0.9\n",
    "    local_max = imregionalmax(cornerImage)\n",
    "    y_coords, x_coords = np.where(local_max==1)\n",
    "    \n",
    "    n_strong = y_coords.size\n",
    "    r = np.zeros(n_strong)\n",
    "    \n",
    "    for i in range(n_strong):\n",
    "        r[i] = float(\"Inf\")\n",
    "        \n",
    "    for i in range(n_strong):\n",
    "        y = y_coords[i]\n",
    "        x = x_coords[i]\n",
    "        \n",
    "        mask = cornerImage[y,x] < c_robust*cornerImage\n",
    "        \n",
    "        ind = np.argwhere(mask) # (x,y)'s that suppress (x_i,y_i) in cornerImage\n",
    "        dist = np.power(np.linalg.norm(ind-[y,x],2,axis=1),2)\n",
    "        r[i] = np.inf if ind.size == 0 else np.amin(dist)\n",
    "    \n",
    "    indices = r.argsort()[-n_best:] # indices of the (x,y) locations of the best corners\n",
    "    best = np.array(list(map(lambda i: (x_coords[i], y_coords[i]), indices)))\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create sift descriptors\n",
    "def sift_descriptors(image, points):\n",
    "    descriptors = np.zeros((points.shape[0],64))\n",
    "    \n",
    "    counter = 0\n",
    "    \n",
    "    for x_sub, y_sub in points:\n",
    "        # pixel is in position (20,20)\n",
    "        x_pix  = int(np.floor(x_sub))\n",
    "        y_pix = int(np.floor(y_sub))\n",
    "        \n",
    "        leftborder = 0 if x_pix-20 < 0 else x_pix-20\n",
    "        rightborder = image.shape[1]-1 if x_pix+19 >= image.shape[1] else x_pix+19\n",
    "        topborder = 0 if y_pix-20 < 0 else y_pix-20\n",
    "        bottomborder = image.shape[0]-1 if y_pix+19 >= image.shape[0] else y_pix+19\n",
    "        neighborhood = image[topborder:(bottomborder+1), leftborder:(rightborder+1)]\n",
    "        \n",
    "        # need to pad neighborhood\n",
    "        if neighborhood.shape != (40,40):\n",
    "            \n",
    "            diffLeft = np.absolute(leftborder-(x_pix-20))\n",
    "            diffRight = np.absolute(rightborder-(x_pix+19))\n",
    "            diffTop = np.absolute(topborder-(y_pix-20))\n",
    "            diffBot = np.absolute(bottomborder-(y_pix+19))\n",
    "            \n",
    "            neighborhood = np.pad(neighborhood, ((diffTop, diffBot),(diffLeft, diffRight)), 'edge')\n",
    "        # Gaussian filter\n",
    "        blurNbrh = cv2.GaussianBlur(src=neighborhood, ksize=(5, 5), sigmaX=1)\n",
    "        # resize\n",
    "        blurNbrh = cv2.resize(blurNbrh, (8,8))\n",
    "        # reshape the neighborhood\n",
    "        blurNbrh = blurNbrh.reshape(64)\n",
    "        # normalization\n",
    "        blurNbrh = (blurNbrh - np.mean(blurNbrh))/np.std(blurNbrh)\n",
    "        descriptors[counter] = blurNbrh\n",
    "        counter = counter + 1\n",
    "    return descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 848,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature matching\n",
    "def matching(descriptor1, descriptor2):\n",
    "    threshold = 0.8\n",
    "    pairs = []\n",
    "    min_dist = 100 #check if there are any inliners/matches\n",
    "    \n",
    "    for i in range(descriptor1.shape[0]):\n",
    "        dists = np.linalg.norm(descriptor1[i] - descriptor2, axis=1)\n",
    "        first_index, second_index = np.argsort(dists)[:2] # indicies for the best and second best points in 2nd image\n",
    "        min_dist = dists[first_index] if min_dist > dists[first_index] else min_dist\n",
    "        \n",
    "        if dists[first_index]/dists[second_index] < threshold:\n",
    "            pairs.append(np.array([i,first_index]))\n",
    "    return (min_dist < 4) , np.array(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 849,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RANSAC\n",
    "def ransac(pairs, points1, points2):\n",
    "    N_max = 30\n",
    "    paired_points1 = np.array(list(map(lambda i: points1[i], pairs[:,0])))\n",
    "    paired_points2 = np.array(list(map(lambda i: points2[i], pairs[:,1])))\n",
    "    \n",
    "    set_of_inliners = []\n",
    "    for k in range(N_max):\n",
    "        random_indices = np.random.choice(pairs.shape[0], 4, replace=False)\n",
    "        \n",
    "        point11 = points1[random_indices[0]]\n",
    "        point12 = points2[random_indices[0]]\n",
    "\n",
    "        point21 = points1[random_indices[1]]\n",
    "        point22 = points2[random_indices[1]]\n",
    "\n",
    "        point31 = points1[random_indices[2]]\n",
    "        point32 = points2[random_indices[2]]\n",
    "\n",
    "        point41 = points1[random_indices[3]]\n",
    "        point42 = points2[random_indices[3]]\n",
    "\n",
    "        H = est_homography(np.array([point11, point21, point31, point41]), np.array([point12, point22, point32, point42]))\n",
    "\n",
    "\n",
    "        Hp = apply_homography(H,paired_points1)\n",
    "        inliners = []\n",
    "        for i in range(pairs.shape[0]):\n",
    "            if np.linalg.norm(Hp[i]-paired_points2[i], 2) < 10:\n",
    "                inliners.append((paired_points1[i], paired_points2[i]))\n",
    "        \n",
    "        set_of_inliners.append(np.array(inliners))\n",
    "        \n",
    "        if len(inliners)/pairs.shape[0] > 0.9:\n",
    "                break\n",
    "    largest_inliner = set_of_inliners[-1]\n",
    "    \n",
    "    if len(set_of_inliners) == N_max:\n",
    "        for inliner in set_of_inliners:\n",
    "            if inliner.shape[0] > largest_inliner.shape[0]:\n",
    "                largest_inliner = inliner\n",
    "    \n",
    "    return est_homography(largest_inliner[:,0], largest_inliner[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 877,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attach image1 to image2\n",
    "def stitch_images(image1, image2):\n",
    "    print(image1.shape, image2.shape)\n",
    "    for y in range(image1.shape[0]):\n",
    "        for x in range(image1.shape[1]):\n",
    "            if image1[y,x] > image2[y,x]:\n",
    "                image2[y,x] =image1[y,x]\n",
    "    return image2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 884,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blend images\n",
    "def blending(image_list, H_list):\n",
    "    # All H in H_list stitch to one base image, the base image is the last image in image_list\n",
    "    # image list of size N, H_list size N-1\n",
    "    # H1 transforms image1 to last image space\n",
    "    \n",
    "    size = image_list[-1].shape # default shape\n",
    "    leftMax, rightMax, topMax, botMax = 0, image_list[-1].shape[1], 0, image_list[-1].shape[0]\n",
    "    \n",
    "    for i in range(image_list.shape[0]-1):\n",
    "        corners = np.array([[0,0], [image_list[i].shape[1], 0], \\\n",
    "                            [0, image_list[i].shape[0]], [image_list[i].shape[1], image_list[i].shape[0]]])\n",
    "        tcorners = apply_homography(H_list[i], corners) # image_i to base image\n",
    "        \n",
    "        leftMax = int(np.floor(min(np.amin(tcorners[:,0]), leftMax)))\n",
    "        topMax = int(np.floor(min(np.amin(tcorners[:,1]), topMax)))\n",
    "        rightMax = int(np.floor(max(np.amax(tcorners[:,0]), rightMax)))\n",
    "        botMax = int(np.floor(max(np.amax(tcorners[:,1]), botMax)))\n",
    "    \n",
    "    size = (rightMax-leftMax, botMax-topMax)\n",
    "    translate = np.eye(3)\n",
    "    translate[0,2] = np.absolute(leftMax)\n",
    "    translate[1,2] = np.absolute(topMax)\n",
    "    \n",
    "    translation_matrices = np.matmul(translate, H_list) # the last H to go from image\n",
    "    \n",
    "    base = stitch_images(cv2.warpPerspective(image_list[-1], translate, size), np.zeros((size[1], size[0])))\n",
    "    \n",
    "    for i in range(image_list.shape[0]-1):\n",
    "        transformed = cv2.warpPerspective(image_list[i], translation_matrices[i], size)\n",
    "        base = stitch_images(transformed, base)\n",
    "    \n",
    "    return base\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 864,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing images, test set\n",
    "input1 = np.divide(cv2.imread(\"../images/set1/1.jpg\", cv2.IMREAD_GRAYSCALE),255.0).astype('float32')\n",
    "input2 = np.divide(cv2.imread(\"../images/set1/2.jpg\", cv2.IMREAD_GRAYSCALE),255.0).astype('float32')\n",
    "input3 = np.divide(cv2.imread(\"../images/set1/3.jpg\", cv2.IMREAD_GRAYSCALE),255.0).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 865,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Harris corner detection\n",
    "corner1 = cv2.cornerHarris(input1, blockSize=5, ksize=5, k=0.06)\n",
    "corner2 = cv2.cornerHarris(input2, blockSize=5, ksize=5, k=0.06)\n",
    "corner3 = cv2.cornerHarris(input3, blockSize=5, ksize=5, k=0.06)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 788,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hcorners1 = amns(corner1, 500)\n",
    "hcorners2 = amns(corner2, 500)\n",
    "hcorners3 = amns(corner3, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 852,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptors1 = sift_descriptors(input1, hcorners1)\n",
    "descriptors2 = sift_descriptors(input2, hcorners2)\n",
    "descriptors3 = sift_descriptors(input3, hcorners3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 853,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag1, matches1 = matching(descriptors1,descriptors2)\n",
    "flag2, matches2 = matching(descriptors2,descriptors3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 854,
   "metadata": {},
   "outputs": [],
   "source": [
    "H1 = ransac(matches1, hcorners1, hcorners2)\n",
    "H2 = ransac(matches2, hcorners3, hcorners2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 879,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(450, 600)"
      ]
     },
     "execution_count": 879,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 885,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(451, 603) (451, 603)\n",
      "(451, 603) (451, 603)\n",
      "(451, 603) (451, 603)\n"
     ]
    }
   ],
   "source": [
    "sol = blending(np.array([input1, input3, input2]), np.array([H1,H2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 795,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image = drawMatches(cv2.imread(\"../images/set1/3.jpg\", cv2.IMREAD_GRAYSCALE), hcorners3[:,[1,0]], cv2.imread(\"../images/set1/1.jpg\", cv2.IMREAD_GRAYSCALE), hcorners1[:,[1,0]], matches3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 796,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('image', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 808,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.11111111, 0.55555556]])"
      ]
     },
     "execution_count": 808,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testH = np.arange(9).reshape((3,3))\n",
    "testx = np.ones(2)\n",
    "testx[0] = 2\n",
    "apply_homography(testH, np.array([testx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 809,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2],\n",
       "       [3, 4, 5],\n",
       "       [6, 7, 8]])"
      ]
     },
     "execution_count": 809,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 9., 12., 15.],\n",
       "        [ 9., 12., 15.],\n",
       "        [ 9., 12., 15.]],\n",
       "\n",
       "       [[36., 39., 42.],\n",
       "        [36., 39., 42.],\n",
       "        [36., 39., 42.]],\n",
       "\n",
       "       [[63., 66., 69.],\n",
       "        [63., 66., 69.],\n",
       "        [63., 66., 69.]]])"
      ]
     },
     "execution_count": 839,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = np.arange(27).reshape((3,3,3))\n",
    "np.matmul(np.ones(9).reshape(3,3), test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
